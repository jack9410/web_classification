{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"img_CNN_multi.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"c8TatWfXX9QV","colab_type":"code","outputId":"0e0d1551-86d2-45e1-9740-8e612e3a7663","executionInfo":{"status":"ok","timestamp":1564962790728,"user_tz":-540,"elapsed":44278,"user":{"displayName":"‍정준모(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"12821859839145449168"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K-xFHd7LNkSu","colab_type":"code","outputId":"feb7f539-9121-4701-d989-fbeb42ba5b56","executionInfo":{"status":"ok","timestamp":1564969316516,"user_tz":-540,"elapsed":3839123,"user":{"displayName":"‍정준모(학부학생/공과대학 컴퓨터과학)","photoUrl":"","userId":"12821859839145449168"}},"colab":{"base_uri":"https://localhost:8080/","height":972}},"source":["from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","import os\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n","from keras import optimizers\n","from keras.callbacks import TensorBoard, ModelCheckpoint,EarlyStopping\n","\n","# dimensions of our images.\n","img_width, img_height = 150, 150\n","\n","train_data_dir = '/content/gdrive/My Drive/projects/web classification/image_data/training_set'\n","validation_data_dir = '/content/gdrive/My Drive/projects/web classification/image_data/test_set'\n","\n","# used to rescale the pixel values from [0, 255] to [0, 1] interval\n","datagen = ImageDataGenerator(rescale=1./255)\n","\n","# automagically retrieve images and their classes for train and validation sets\n","train_generator = datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(img_width, img_height),\n","        batch_size=16,\n","        class_mode='categorical',\n","        shuffle=True)\n","\n","validation_generator = datagen.flow_from_directory(\n","        validation_data_dir,\n","        target_size=(img_width, img_height),\n","        batch_size=32,\n","        class_mode='categorical',\n","        shuffle=True)\n","\n","model = Sequential()\n","model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Convolution2D(32, 3, 3))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Convolution2D(32, 3, 3))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Convolution2D(32, 3, 3))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(3))\n","model.add(Activation('softmax'))#sigmoid\n","\n","tbCallBack=[]\n","tbCallBack=TensorBoard(log_dir='./Graph_Adam32')\n","tbCallBackchptk=ModelCheckpoint('/content/gdrive/My Drive/projects/web classification/data_out/weightsAdam32.h5',save_weights_only=True)\n","tbCallBackearlyStop=EarlyStopping(patience=3)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam', #rmsprop\n","              metrics=['accuracy'])\n","#model.summary()\n","nb_epoch = 20\n","nb_train_samples = 5200#9576#2048\n","nb_validation_samples = 900#1245#832\n","\n","model.fit_generator(\n","        train_generator,\n","        samples_per_epoch=nb_train_samples,\n","        nb_epoch=nb_epoch,\n","        validation_data=validation_generator,\n","        nb_val_samples=nb_validation_samples, callbacks=[tbCallBack,tbCallBackchptk,tbCallBackearlyStop])\n","model.save('/content/gdrive/My Drive/projects/web classification/data_out/3class.h5')\n","print(model.evaluate_generator(validation_generator, nb_validation_samples))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found 4091 images belonging to 3 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0804 23:53:28.403321 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n","W0804 23:53:28.459259 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0804 23:53:28.466781 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0804 23:53:28.504835 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Found 2264 images belonging to 3 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n","W0804 23:53:28.592482 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0804 23:53:28.609023 140479706109824 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0804 23:53:31.326832 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0804 23:53:31.360635 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., callbacks=[<keras.ca..., steps_per_epoch=325, epochs=20, validation_steps=900)`\n","W0804 23:53:31.509496 140479706109824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0804 23:53:35.618608 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","W0804 23:53:35.620224 140479706109824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n","  'to RGBA images')\n"],"name":"stderr"},{"output_type":"stream","text":["325/325 [==============================] - 2814s 9s/step - loss: 0.9036 - acc: 0.5773 - val_loss: 0.8732 - val_acc: 0.6571\n","Epoch 2/20\n","325/325 [==============================] - 413s 1s/step - loss: 0.7410 - acc: 0.7020 - val_loss: 0.7048 - val_acc: 0.6940\n","Epoch 3/20\n","325/325 [==============================] - 415s 1s/step - loss: 0.6848 - acc: 0.7310 - val_loss: 1.2211 - val_acc: 0.4869\n","Epoch 4/20\n","325/325 [==============================] - 413s 1s/step - loss: 0.5959 - acc: 0.7707 - val_loss: 0.7819 - val_acc: 0.6924\n","Epoch 5/20\n","325/325 [==============================] - 416s 1s/step - loss: 0.5280 - acc: 0.7979 - val_loss: 0.6922 - val_acc: 0.7456\n","Epoch 6/20\n","325/325 [==============================] - 414s 1s/step - loss: 0.4307 - acc: 0.8411 - val_loss: 0.5796 - val_acc: 0.7793\n","Epoch 7/20\n","325/325 [==============================] - 420s 1s/step - loss: 0.3762 - acc: 0.8560 - val_loss: 0.5839 - val_acc: 0.7947\n","Epoch 8/20\n","325/325 [==============================] - 417s 1s/step - loss: 0.3420 - acc: 0.8756 - val_loss: 0.7181 - val_acc: 0.7611\n","Epoch 9/20\n","325/325 [==============================] - 415s 1s/step - loss: 0.2825 - acc: 0.9000 - val_loss: 0.6714 - val_acc: 0.7999\n","[0.6701932082797838, 0.7999233555800407]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C5b7EZtjSsWS","colab_type":"code","colab":{}},"source":["  from google.colab.patches import cv2_imshow\n","from keras.models import load_model\n","import cv2\n","import numpy as np\n","import glob\n","\n","def writeResultOnImage(openCVImage, resultText):\n","    # ToDo: this function may take some further fine-tuning to show the text well given any possible image size\n","    SCALAR_BLUE = (255.0, 0.0, 0.0)\n","    imageHeight, imageWidth, sceneNumChannels = openCVImage.shape\n","\n","    # choose a font\n","    fontFace = cv2.FONT_HERSHEY_TRIPLEX\n","\n","    # chose the font size and thickness as a fraction of the image size\n","    fontScale = 1.0\n","    fontThickness = 3\n","\n","    # make sure font thickness is an integer, if not, the OpenCV functions that use this may crash\n","    fontThickness = int(fontThickness)\n","\n","    upperLeftTextOriginX = int(imageWidth * 0.05)\n","    upperLeftTextOriginY = int(imageHeight * 0.05)\n","\n","    textSize, baseline = cv2.getTextSize(resultText, fontFace, fontScale, fontThickness)\n","    textSizeWidth, textSizeHeight = textSize\n","\n","    # calculate the lower left origin of the text area based on the text area center, width, and height\n","    lowerLeftTextOriginX = upperLeftTextOriginX\n","    lowerLeftTextOriginY = upperLeftTextOriginY + textSizeHeight\n","\n","    # write the text on the image\n","    cv2.putText(openCVImage, resultText, (lowerLeftTextOriginX, lowerLeftTextOriginY), fontFace, fontScale, SCALAR_BLUE, fontThickness)\n","# end function\n","\n","# dimensions of our images\n","model=load_model('/content/gdrive/My Drive/projects/web classification/data_out/3class.h5')\n","model.load_weights('/content/gdrive/My Drive/projects/web classification/data_out/weightsAdam32.h5')\n","#model.summary()\n","\n","images= glob.glob(\"/content/gdrive/My Drive/projects/web classification/image_data/test_set/gamble/*.jpg\")\n","\n","for i in images:\n","    image = cv2.imread(i)\n","#     print(image.shape)\n","    imgr = np.resize(image, (150, 150,3))\n","#     print(imgr.shape)\n","    img = np.reshape(imgr, [1, 150, 150, 3])\n","    classes = model.predict(img)\n","    classification=np.argmax(classes)\n","#     cv2.namedWindow('Prediction',cv2.WINDOW_NORMAL)\n","#     cv2.resizeWindow('Prediction', 500,500)\n","    print(classes)\n","    print(classification)\n","    prediction=''\n","    if classification==1:\n","        prediction='normal'\n","    elif classification==0:\n","        prediction='gamble'\n","    elif classification==2:\n","        prediction='game'\n","\n","    writeResultOnImage(image,prediction)\n","    cv2_imshow(image)\n","#     cv2.waitKey(0)\n","#     cv2.destroyAllWindows()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WHB3HTB4l9VW","colab_type":"text"},"source":[""]}]}